{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) The category of each text article must depend on the meaning of its content. Explain why\n",
    "Naive-Bayes assumption is not too unrealistic for text categorization problem.\n",
    "\n",
    "Ans.\n",
    "Bag of Words concepts(text categorization problems) treat each word individually and the order in which the words occur does not matter. Using the naive-bayes assumption of conditional independence, a lot of the dependence among features can be explained away by the underlying class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)Train the model based on the training data by MLE. For each class k among 4\n",
    "different classes, you should learn the parameter φ(j|y)=k, which is the conditional probability p(x(j) |y = k). You should also learn the parameter φ(y=k), which is the prior probability of each class p(y = k). Report the confusion matrix and training accuracy by predicting the class labels of the training set by your trained Bernoulli Naive-Bayes model.\n",
    "\n",
    "Ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.sparse as sparse\n",
    "import math\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\dhana\\\\Courses\\\\MSBA\\\\Spring_Sem\\\\IDS575\\\\Assignment3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(file):\n",
    "    datafile = open(file, 'r') \n",
    "    dataLines = datafile.readlines() \n",
    "    strip = [x.rstrip(\"\\n\") for x in dataLines]\n",
    "    dataTokens = [re.split(\":| \",x) for x in strip]\n",
    "    Y = [int(x[0]) for x in dataTokens]\n",
    "    Xlist = [np.reshape(np.array(x[1:len(x)],dtype=np.int32),(-1,2)) for x in dataTokens] #word,count array\n",
    "    Xlist = [np.insert(Xlist[x],0,x,axis=1) for x in range(len(Xlist))]#appending instance number\n",
    "    Xdata = np.concatenate(tuple(Xlist),axis=0) #concatenating all the instance arrays to one array \n",
    "    X = csr_matrix((Xdata[:,2], (Xdata[:,0], Xdata[:,1])))#sparse matrix\n",
    "    Bernoulli_X = csr_matrix((np.ones((Xdata.shape[0],),dtype=np.int32), (Xdata[:,0], Xdata[:,1])))# bernoulli csr_matrix (word in doc implies 1 else 0)\n",
    "    return([np.array(Y),X,Bernoulli_X,Xdata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data(\"articles.train\")\n",
    "test = data(\"articles.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = train[0]-1\n",
    "Ytest = test[0]-1\n",
    "Xtrain = train[1][:,1:]\n",
    "Xtest = test[1][:,1:]\n",
    "Berno_Xtrain = train[2][:,1:]\n",
    "Berno_Xtest = test[2][:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique(array):\n",
    "    unique, count = np.unique(np.asarray(array), return_counts=True)\n",
    "    return(dict(zip(unique, count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def split(cdata):\n",
    "    cdata1 = cdata[:1000,:]\n",
    "    cdata2 = cdata[1000:2000,:]\n",
    "    cdata3 = cdata[2000:3000,:]\n",
    "    cdata4 = cdata[-1000:,:]\n",
    "    return([cdata1,cdata2,cdata3,cdata4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitM = split(Berno_Xtrain)\n",
    "frequencyM = split(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BernoulliNB(csr,X):\n",
    "    prior=[]\n",
    "    for i in range(4):\n",
    "        prior.append(csr[i].sum(axis=0))\n",
    "    \n",
    "    if prior[0].shape[1]<X.shape[1]:\n",
    "        for i in range(4):\n",
    "            prior[i]=np.hstack((prior[i],np.zeros((1,X.shape[1]-prior[i].shape[1]))))      \n",
    "\n",
    "    cprob=[]\n",
    "    for i in range(4):\n",
    "        cprob.append(X.multiply(np.log((prior[i])/(1000))).tocsr())\n",
    "    \n",
    "    return(np.hstack([cprob[0].sum(axis=1),cprob[1].sum(axis=1),cprob[2].sum(axis=1),cprob[3].sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gitap\\.conda\\envs\\bas575\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 99.9,   0. ,   0. ,   0.1],\n",
       "       [  0.1,  99.2,   0.3,   0.4],\n",
       "       [  0.2,   0.2,  99.5,   0.1],\n",
       "       [  0. ,   0. ,   0. , 100. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Ytrain,np.argmax(BernoulliNB(splitM,Berno_Xtrain),axis=1))/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gitap\\.conda\\envs\\bas575\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[100.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 94.33333333,   5.33333333,   0.        ,   0.33333333],\n",
       "       [ 92.        ,   0.        ,   7.83333333,   0.16666667],\n",
       "       [ 94.5       ,   0.        ,   0.16666667,   5.33333333]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Ytest,np.argmax(BernoulliNB(splitM,Berno_Xtest),axis=1))/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultinomialNB(csr,X):\n",
    "    prior=[]\n",
    "    for i in range(4):\n",
    "        prior.append(csr[i].sum(axis=0))\n",
    "    \n",
    "    if prior[0].shape[1]<X.shape[1]:\n",
    "        for i in range(4):\n",
    "            prior[i]=np.hstack((prior[i],np.zeros((1,X.shape[1]-prior[i].shape[1]))))\n",
    "            \n",
    "    cprob=[]\n",
    "    for i in range(4):\n",
    "        cprob.append(X.multiply(np.log(prior[i]/(prior[i].sum(axis=1)))).tocsr())\n",
    "        \n",
    "    return(np.hstack([cprob[0].sum(axis=1),cprob[1].sum(axis=1),cprob[2].sum(axis=1),cprob[3].sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultinomialNB_laplace(csr,X):\n",
    "    prior=[]\n",
    "    for i in range(4):\n",
    "        prior.append(csr[i].sum(axis=0))\n",
    "    \n",
    "    if prior[0].shape[1]<X.shape[1]:\n",
    "        for i in range(4):\n",
    "            prior[i]=np.hstack((prior[i],np.zeros((1,X.shape[1]-prior[i].shape[1]))))\n",
    "            \n",
    "    cprob=[]\n",
    "    for i in range(4):\n",
    "        cprob.append(X.multiply(np.log(prior[i]+1/(prior[i].sum(axis=1)+51949))).tocsr())\n",
    "        \n",
    "    return(np.hstack([cprob[0].sum(axis=1),cprob[1].sum(axis=1),cprob[2].sum(axis=1),cprob[3].sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gitap\\.conda\\envs\\bas575\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[99.9,  0.1,  0. ,  0. ],\n",
       "       [ 0.1, 99.8,  0.1,  0. ],\n",
       "       [ 0.2,  0.4, 99.4,  0. ],\n",
       "       [ 0. ,  0.1,  0. , 99.9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Ytrain,np.argmax(MultinomialNB(frequencyM,Xtrain),axis=1))/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gitap\\.conda\\envs\\bas575\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[100.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 94.33333333,   5.5       ,   0.16666667,   0.        ],\n",
       "       [ 92.        ,   0.16666667,   7.83333333,   0.        ],\n",
       "       [ 94.66666667,   0.        ,   0.16666667,   5.16666667]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Ytest,np.argmax(MultinomialNB(frequencyM,Xtest),axis=1))/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Learn the model parameters again by performing Laplace smoothing (in Lecture\n",
    "Notes #09a). Report the new confusion matrix and training accuracy when predicting\n",
    "on training data. Report another confusion matrix and test accuracy when predicting on\n",
    "test data. (Note: You cannot report test statistics without Laplace smoothing because\n",
    "there are unseen words in the test data as we experienced at Problem 5 in Homework 2)\n",
    "\n",
    "Ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BernoulliNB_laplace(csr,X):\n",
    "    prior=[]\n",
    "    for i in range(4):\n",
    "        prior.append(csr[i].sum(axis=0))\n",
    "    \n",
    "    if prior[0].shape[1]<X.shape[1]:\n",
    "        for i in range(4):\n",
    "            prior[i]=np.hstack((prior[i],np.zeros((1,X.shape[1]-prior[i].shape[1]))))      \n",
    "\n",
    "    cprob=[]\n",
    "    for i in range(4):\n",
    "        cprob.append(X.multiply(np.log((prior[i]+1)/(1002))).tocsr())\n",
    "    \n",
    "    return(np.hstack([cprob[0].sum(axis=1),cprob[1].sum(axis=1),cprob[2].sum(axis=1),cprob[3].sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 95.1,   0.1,   0. ,   4.8],\n",
       "       [  0.3,  83.7,   0.1,  15.9],\n",
       "       [  0.4,   0.1,  94.3,   5.2],\n",
       "       [  0. ,   0. ,   0. , 100. ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Ytrain,np.argmax(BernoulliNB_laplace(splitM,Berno_Xtrain),axis=1))/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.33333333,  0.33333333,  0.16666667, 22.16666667],\n",
       "       [ 0.33333333, 63.        ,  0.16666667, 36.5       ],\n",
       "       [ 0.33333333,  0.        , 76.66666667, 23.        ],\n",
       "       [ 0.        ,  0.16666667,  0.5       , 99.33333333]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Ytest,np.argmax(BernoulliNB_laplace(splitM,Berno_Xtest),axis=1))/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Report part (c) with multinomial Naive-Bayes model. Report correspondingly\n",
    "to part (c).\n",
    "\n",
    "Ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultinomailNB_laplace(csr,X):\n",
    "    prior=[]\n",
    "    for i in range(4):\n",
    "        prior.append(csr[i].sum(axis=0))\n",
    "    \n",
    "    if prior[0].shape[1]<X.shape[1]:\n",
    "        for i in range(4):\n",
    "            prior[i]=np.hstack((prior[i],np.zeros((1,X.shape[1]-prior[i].shape[1]))))\n",
    "            \n",
    "    cprob=[]\n",
    "    for i in range(4):\n",
    "        cprob.append(X.multiply(np.log(prior[i]+1/(prior[i].sum(axis=1)+51949))).tocsr())\n",
    "        \n",
    "    return(np.hstack([cprob[0].sum(axis=1),cprob[1].sum(axis=1),cprob[2].sum(axis=1),cprob[3].sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99.7,   0. ,   0. ,   0.3],\n",
       "       [  0.1,  96.7,   0.2,   3. ],\n",
       "       [  0.3,   0.1,  99.2,   0.4],\n",
       "       [  0. ,   0. ,   0. , 100. ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Ytrain,np.argmax(MultinomialNB_laplace(frequencyM,Xtrain),axis=1))/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87.66666667,  0.33333333,  1.33333333, 10.66666667],\n",
       "       [ 0.5       , 82.66666667,  0.        , 16.83333333],\n",
       "       [ 0.83333333,  0.16666667, 91.        ,  8.        ],\n",
       "       [ 0.33333333,  0.66666667,  0.33333333, 98.66666667]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Ytest,np.argmax(MultinomialNB_laplace(frequencyM,Xtest),axis=1))/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Compare and contrast the results from part (c) and (d). Justify why one works better than the other in our dataset. Explain, more in general, the weakness of NaıveBayes models by comparing Bernoulli event model and multinomial event model. (Hint: Think about what happen if the same word occurs multiple times in an article)\n",
    "\n",
    "Ans.\n",
    "The multinomial laplace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
